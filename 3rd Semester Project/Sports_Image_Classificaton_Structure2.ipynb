{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a566a9f7-4e3d-44e6-88cc-62b52823b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429b06dd-b1a7-478c-9604-05add3c399fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\",\n",
    "                             )\n",
    "data_validation_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\"\n",
    "                             )\n",
    "data_train_characteristics=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8f6802-1aad-417b-bda5-af1d38c5fe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\train\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                             )\n",
    "validation_data_set=data_validation_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\valid\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                             )\n",
    "test_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\test\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7aaa28a-0452-4d45-abb3-efbc2ed46946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186ea826-548a-45b1-89ae-36186016f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(256,256,3))\n",
    "\n",
    "conv_1=Conv2D(16,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(input_layer)\n",
    "max_1=MaxPooling2D(strides=1,pool_size=(3,3))(conv_1)\n",
    "\n",
    "conv_2=Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_1)\n",
    "max_2=MaxPooling2D(strides=1,pool_size=(3,3))(conv_2)\n",
    "\n",
    "conv_3=Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_2)\n",
    "max_3=MaxPooling2D(strides=1,pool_size=(3,3))(conv_3)\n",
    "\n",
    "conv_4=Conv2D(128,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_3)\n",
    "max_4=MaxPooling2D(strides=1,pool_size=(3,3))(conv_4)\n",
    "\n",
    "flatten=Flatten()(max_4)\n",
    "\n",
    "dense_1=Dense(8,activation=\"relu\")(flatten)\n",
    "dense_2=Dense(4,activation=\"relu\")(dense_1)\n",
    "output_layer=Dense(2,activation=\"softmax\")(dense_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca2aa18-0fb3-4d67-ac27-2ccbd1da586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Model(input_layer,output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.002),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85202b5-324b-43ab-8b5f-eba49fded285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "4/4 [==============================] - ETA: 0s - loss: 30.3185 - accuracy: 0.8960  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\WorkaStation\\PythonEnvironments\\Env1_Skeleton\\env1-08july2023\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 341s 87s/step - loss: 30.3185 - accuracy: 0.8960 - val_loss: 0.7344 - val_accuracy: 0.5000\n",
      "Epoch 2/7\n",
      "4/4 [==============================] - 340s 85s/step - loss: 0.3932 - accuracy: 0.8960 - val_loss: 0.8258 - val_accuracy: 0.5000\n",
      "Epoch 3/7\n",
      "4/4 [==============================] - 312s 76s/step - loss: 0.3956 - accuracy: 0.8960 - val_loss: 1.0947 - val_accuracy: 0.5000\n",
      "Epoch 4/7\n",
      "4/4 [==============================] - 304s 75s/step - loss: 0.4566 - accuracy: 0.8960 - val_loss: 0.7866 - val_accuracy: 0.5000\n",
      "Epoch 5/7\n",
      "4/4 [==============================] - 300s 77s/step - loss: 0.4025 - accuracy: 0.8960 - val_loss: 0.7239 - val_accuracy: 0.5000\n",
      "Epoch 6/7\n",
      "4/4 [==============================] - 22834s 7586s/step - loss: 0.3436 - accuracy: 0.8960 - val_loss: 0.8010 - val_accuracy: 0.5000\n",
      "Epoch 7/7\n",
      "4/4 [==============================] - 220s 51s/step - loss: 0.3175 - accuracy: 0.8960 - val_loss: 0.7181 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data_set,\n",
    "                 validation_data=validation_data_set,\n",
    "                 epochs=7,\n",
    "                 batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1-08july2023",
   "language": "python",
   "name": "env1-08july2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
