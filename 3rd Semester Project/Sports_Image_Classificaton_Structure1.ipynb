{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a028c6f-c824-485e-8e76-f25237ce8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0629a844-726f-4d45-bf73-2b5712b3f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\WorkaStation\\\\PythonEnvironments\\\\Env1_Skeleton\\\\env1-08july2023'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c90559d-6991-4c19-bbfa-5c94b657d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\",\n",
    "                             )\n",
    "data_validation_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\"\n",
    "                             )\n",
    "data_train_characteristics=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23038887-0ed7-48b8-8e41-08dc3e2c44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\train\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                             )\n",
    "validation_data_set=data_validation_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\valid\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                             )\n",
    "test_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\test\\\\\",\n",
    "                                                             target_size=(256,256),\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214512a4-993e-4e7b-a2be-cc2443c345e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4809c9-c8f0-44ae-9d83-3e3be8a68e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(256,256,3))\n",
    "\n",
    "conv_1=Conv2D(16,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(input_layer)\n",
    "max_1=MaxPooling2D(strides=1,pool_size=(3,3))(conv_1)\n",
    "\n",
    "conv_3=Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_1)\n",
    "max_2=MaxPooling2D(strides=1,pool_size=(3,3))(conv_3)\n",
    "\n",
    "conv_4=Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_2)\n",
    "max_3=MaxPooling2D(strides=1,pool_size=(3,3))(conv_4)\n",
    "\n",
    "flatten=Flatten()(max_3)\n",
    "\n",
    "dense_1=Dense(8,activation=\"relu\")(flatten)\n",
    "dense_2=Dense(4,activation=\"relu\")(dense_1)\n",
    "output_layer=Dense(2,activation=\"softmax\")(dense_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53dcede5-6bee-41cf-8e54-57b9eca3ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Model(input_layer,output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.002),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab2cb31-d680-4a4e-a969-d139d64fc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "4/4 [==============================] - ETA: 0s - loss: 49.3657 - accuracy: 0.4480 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\WorkaStation\\PythonEnvironments\\Env1_Skeleton\\env1-08july2023\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 93s 24s/step - loss: 49.3657 - accuracy: 0.4480 - val_loss: 0.9604 - val_accuracy: 0.5000\n",
      "Epoch 2/7\n",
      "4/4 [==============================] - 82s 20s/step - loss: 0.3619 - accuracy: 0.9360 - val_loss: 0.8045 - val_accuracy: 0.4000\n",
      "Epoch 3/7\n",
      "4/4 [==============================] - 82s 21s/step - loss: 0.6989 - accuracy: 0.9040 - val_loss: 1.1500 - val_accuracy: 0.5000\n",
      "Epoch 4/7\n",
      "4/4 [==============================] - 80s 19s/step - loss: 0.3976 - accuracy: 0.8080 - val_loss: 0.7648 - val_accuracy: 0.3000\n",
      "Epoch 5/7\n",
      "4/4 [==============================] - 80s 20s/step - loss: 0.1806 - accuracy: 0.9520 - val_loss: 0.8982 - val_accuracy: 0.5000\n",
      "Epoch 6/7\n",
      "4/4 [==============================] - 78s 20s/step - loss: 0.0927 - accuracy: 0.9760 - val_loss: 4.3510 - val_accuracy: 0.5000\n",
      "Epoch 7/7\n",
      "4/4 [==============================] - 64s 16s/step - loss: 0.4513 - accuracy: 0.8640 - val_loss: 5.9493 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data_set,\n",
    "                 validation_data=validation_data_set,\n",
    "                 epochs=7,\n",
    "                 batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70c86d-bb76-46ec-87b4-ad5023cc977d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1-08july2023",
   "language": "python",
   "name": "env1-08july2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
