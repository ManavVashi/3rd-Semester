{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e496fd-d9ea-4840-8b35-bebeff3ad605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3969a9e5-354d-41df-ba28-b2fb1a92e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\",\n",
    "                             )\n",
    "data_validation_characteristics=ImageDataGenerator(rescale=1./255,\n",
    "                             height_shift_range=10.0,\n",
    "                             width_shift_range=10.0,\n",
    "                               rotation_range=180,\n",
    "                              zoom_range=1.75,\n",
    "                              brightness_range=(0.1,0.9),\n",
    "                              channel_shift_range=200.0,\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              samplewise_center=True,\n",
    "                              featurewise_center=True,\n",
    "                              fill_mode=\"reflect\"\n",
    "                             )\n",
    "data_train_characteristics=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d087e234-5920-4e6d-804a-9ab7d3ea4e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\train\\\\\",\n",
    "                                                             target_size=(224,224),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                             )\n",
    "validation_data_set=data_validation_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\valid\\\\\",\n",
    "                                                             target_size=(224,224),\n",
    "                                                              batch_size=32,\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                             )\n",
    "test_data_set=data_train_characteristics.flow_from_directory(\"C:\\\\Users\\\\HP\\\\Documents\\\\Data_Set_4(Sports_Image)\\\\test\\\\\",\n",
    "                                                             target_size=(224,224),\n",
    "                                                              color_mode=\"rgb\",\n",
    "                                                              class_mode=\"categorical\"\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceaacf0d-8c60-4111-95ba-68ed101f1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7d6589-6374-443f-be1c-d90c5419ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(224,224,3))\n",
    "\n",
    "conv_1=Conv2D(16,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(input_layer)\n",
    "conv_2=Conv2D(16,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_1)\n",
    "max_1=MaxPooling2D(strides=1,pool_size=(3,3))(conv_2)\n",
    "\n",
    "conv_3=Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_1)\n",
    "conv_4=Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_3)\n",
    "max_2=MaxPooling2D(strides=1,pool_size=(3,3))(conv_4)\n",
    "\n",
    "conv_5=Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_2)\n",
    "conv_6=Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_5)\n",
    "conv_7=Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_6)\n",
    "max_3=MaxPooling2D(strides=1,pool_size=(3,3))(conv_7)\n",
    "\n",
    "conv_8=Conv2D(128,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(max_3)\n",
    "conv_9=Conv2D(128,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_8)\n",
    "conv_10=Conv2D(128,kernel_size=(3,3),padding=\"valid\",activation=\"relu\")(conv_9)\n",
    "max_4=MaxPooling2D(strides=1,pool_size=(3,3))(conv_10)\n",
    "\n",
    "flatten=Flatten()(max_4)\n",
    "\n",
    "dense_1=Dense(32,activation=\"relu\")(flatten)\n",
    "dense_2=Dense(8,activation=\"relu\")(dense_1)\n",
    "output_layer=Dense(2,activation=\"softmax\")(dense_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8b93b5-d2ce-4d69-834e-7b7d005e7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Model(input_layer,output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.002),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d64ca24-f421-43ac-bfbf-582bfbb68679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "4/4 [==============================] - ETA: 0s - loss: 35.5116 - accuracy: 0.8960  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\WorkaStation\\PythonEnvironments\\Env1_Skeleton\\env1-08july2023\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 556s 150s/step - loss: 35.5116 - accuracy: 0.8960 - val_loss: 1.7080 - val_accuracy: 0.5000\n",
      "Epoch 2/7\n",
      "4/4 [==============================] - 566s 139s/step - loss: 0.4083 - accuracy: 0.8960 - val_loss: 2.1359 - val_accuracy: 0.5000\n",
      "Epoch 3/7\n",
      "4/4 [==============================] - 532s 134s/step - loss: 0.3627 - accuracy: 0.8960 - val_loss: 1.1503 - val_accuracy: 0.5000\n",
      "Epoch 4/7\n",
      "4/4 [==============================] - 470s 122s/step - loss: 0.4352 - accuracy: 0.8960 - val_loss: 0.6991 - val_accuracy: 0.5000\n",
      "Epoch 5/7\n",
      "4/4 [==============================] - 493s 127s/step - loss: 0.4642 - accuracy: 0.8960 - val_loss: 1.4356 - val_accuracy: 0.5000\n",
      "Epoch 6/7\n",
      "4/4 [==============================] - 412s 102s/step - loss: 0.3513 - accuracy: 0.8960 - val_loss: 1.0256 - val_accuracy: 0.5000\n",
      "Epoch 7/7\n",
      "4/4 [==============================] - 442s 116s/step - loss: 0.3437 - accuracy: 0.8960 - val_loss: 1.3699 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data_set,\n",
    "                 validation_data=validation_data_set,\n",
    "                 epochs=7,\n",
    "                 batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7e17c72-b183-4978-ae5b-13257133d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3def09dd-2133-46f9-908c-4c38a6670ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread(\"C:\\\\Users\\\\HP\\\\Pictures\\\\Screenshots\\\\Screenshot 2023-10-15 151027.png\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc736a2e-ad21-48d0-83f5-1af90cec313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=(np.expand_dims(img,0))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c78c304-67a9-4a74-aee5-5b0cd46e62b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 419ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3172306e-08, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPrediction=model.predict(img)\n",
    "myPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2b815-9d1b-41ed-926b-574f2f7acaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1-08july2023",
   "language": "python",
   "name": "env1-08july2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
